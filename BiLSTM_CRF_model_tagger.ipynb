{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "from kashgari.tasks.labeling import BiLSTM_CRF_Model\n",
    "from kashgari.embeddings import BertEmbedding\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA\n",
    "SAVE_DATA_noclus_tr = \"Save/noclus_bistlstm_dataset_train.csv\"\n",
    "SAVE_DATA_noclus_ts = \"Save/noclus_bistlstm_dataset_test.csv\"\n",
    "SAVE_DATA_noclus_dv = \"Save/noclus_bistlstm_dataset_dev.csv\"\n",
    "\n",
    "train = open(SAVE_DATA_noclus_tr).read()\n",
    "test = open(SAVE_DATA_noclus_ts).read()\n",
    "val = open(SAVE_DATA_noclus_dv).read()\n",
    "\n",
    "def file_convert2format(file):\n",
    "    split_file = file.split(\"\\n\\t\\n\")\n",
    "    t_x = []\n",
    "    t_y = []\n",
    "    for sent in split_file:\n",
    "        t_x.append([])\n",
    "        t_y.append([])\n",
    "        sent_split = sent.split(\"\\n\")\n",
    "        for lines in sent_split:\n",
    "            line_split = lines.split(\"\\t\")\n",
    "            t_x[-1].append(line_split[0])\n",
    "            t_y[-1].append(line_split[1])\n",
    "            \n",
    "    return(t_x,t_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = file_convert2format(train)\n",
    "test_x, test_y = file_convert2format(test)\n",
    "valid_x, valid_y = file_convert2format(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "total_x = np.array(list(train_x + test_x + valid_x))\n",
    "total_y = np.array(list(train_y + test_y + valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4108\n",
      "4108\n",
      "617 3081 410\n"
     ]
    }
   ],
   "source": [
    "print(len(total_x))\n",
    "print(len(total_y))\n",
    "index = np.array(list(range(len(total_x))))    \n",
    "\n",
    "## shuffling the dataset\n",
    "np.random.shuffle(index)\n",
    "total_x = total_x[index]\n",
    "total_y = total_y[index]\n",
    "\n",
    "## dividing the dataset\n",
    "train = int(len(total_x)*0.75)          ## 75% of the 100%\n",
    "val = int((len(total_x) - train)*0.4)  ## 40% of the 30%\n",
    "test = (len(total_x)-train-val)        ## 60% of the 30%\n",
    "print(test,train,val)\n",
    "\n",
    "## the dataset\n",
    "## tokens\n",
    "train_x = list(total_x[:train])\n",
    "test_x = list(total_x[train:(train+test)])\n",
    "valid_x = list(total_x[(train+test):])\n",
    "\n",
    "## labels\n",
    "train_y = list(total_y[:train])\n",
    "test_y = list(total_y[train:(train+test)])\n",
    "valid_y = list(total_y[(train+test):])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_blstm': {'units': 32, 'return_sequences': True}, 'layer_dropout': {'rate': 0.8}, 'layer_time_distributed': {}, 'layer_activation': {'activation': 'softmax'}}\n"
     ]
    }
   ],
   "source": [
    "## using pretrained embeddings to fine tune for task\n",
    "## BERT_Tiny_2_128\n",
    "## cased_L-12_H-768_A-12\n",
    "\n",
    "# bert_embed = BertEmbedding('BERTmodels/BERT_Tiny_2_128')\n",
    "# model = BiLSTM_CRF_Model()\n",
    "# hyper = model.default_hyper_parameters()\n",
    "\n",
    "# hyper['layer_blstm']['units'] = 32\n",
    "# hyper['layer_dropout']['rate'] = 0.8\n",
    "# hyper['layer_activation']['activation'] = 'softmax'\n",
    "# model = BiLSTM_CRF_Model(bert_embed, sequence_length=50,hyper_parameters=hyper)\n",
    "\n",
    "print(hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Model training\n",
    "# model.fit(train_x, train_y, valid_x, valid_y,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 14:23:34,174 [DEBUG] kashgari - predict seq_length: None, input: (2, 617, 93)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 52ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 14:23:35,307 [DEBUG] kashgari - predict output: (617, 93)\n",
      "2021-05-05 14:23:35,308 [DEBUG] kashgari - predict output argmax: [[0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " ...\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "    CLAIM     0.6455    0.5462    0.5917       130\n",
      "      ACT     0.5070    0.4286    0.4645        84\n",
      "\n",
      "micro avg     0.5912    0.5000    0.5418       214\n",
      "macro avg     0.5911    0.5000    0.5418       214\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'detail': {'CLAIM': {'precision': 0.6454545454545455,\n",
       "   'recall': 0.5461538461538461,\n",
       "   'f1-score': 0.5916666666666667,\n",
       "   'support': 130},\n",
       "  'ACT': {'precision': 0.5070422535211268,\n",
       "   'recall': 0.42857142857142855,\n",
       "   'f1-score': 0.46451612903225803,\n",
       "   'support': 84}},\n",
       " 'precision': 0.5911244869386241,\n",
       " 'recall': 0.5,\n",
       " 'f1-score': 0.5417571098382072,\n",
       " 'support': 214}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 14:24:01,109 [DEBUG] kashgari - ------------------------------------------------\n",
      "2021-05-05 14:24:01,110 [DEBUG] kashgari - Loaded transformer model's vocab\n",
      "2021-05-05 14:24:01,111 [DEBUG] kashgari - config_path       : BERTmodels/BERT_Tiny_2_128/bert_config.json\n",
      "2021-05-05 14:24:01,112 [DEBUG] kashgari - vocab_path      : BERTmodels/BERT_Tiny_2_128/vocab.txt\n",
      "2021-05-05 14:24:01,112 [DEBUG] kashgari - checkpoint_path : BERTmodels/BERT_Tiny_2_128/bert_model.ckpt\n",
      "2021-05-05 14:24:01,113 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused0]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]']\n",
      "2021-05-05 14:24:01,114 [DEBUG] kashgari - ------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model data will save to 'saved_act_claim_model' folder\n",
    "# model.save('saved_act_claim_model_1000_BERTtiny_bilstmcrf_2')\n",
    "loaded_model = BiLSTM_CRF_Model.load_model('saved_act_claim_model_1000_BERTtiny_bilstmcrf_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 14:25:11,868 [DEBUG] kashgari - predict seq_length: None, input: (2, 1, 52)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clinton', 'is', 'to', 'address', 'the', 'gathering', 'on', 'Thursday', ',', 'amid', 'intense', 'criticism', 'from', 'environmental', 'advocates', 'who', 'say', 'his', 'Administration', 'is', 'not', 'taking', 'a', 'firm', 'enough', 'stance', 'in', 'negotiations', ',', 'scheduled', 'to', 'be', 'concluded', 'in', 'December', 'in', 'Kyoto', ',', 'Japan', ',', 'aimed', 'at', 'setting', 'binding', 'targets', 'for', 'reducing', 'greenhouse', 'gases', '.']\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 14:25:11,943 [DEBUG] kashgari - predict output: (1, 52)\n",
      "2021-05-05 14:25:11,944 [DEBUG] kashgari - predict output argmax: [[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 3 1 1 1 4 2 2 2 2 2 1 2 2 2 2 2 2\n",
      "  2 2 1 1 1 1 1 4 2 2 2 2 2 2 1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-ACT',\n",
       "  'I-ACT',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'O',\n",
       "  'I-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'I-CLAIM',\n",
       "  'O']]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load predict model\n",
    "print(test_x[291])\n",
    "loaded_model.predict(test_x[291:292])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bilstm_crf",
   "language": "python",
   "name": "bilstm_crf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
