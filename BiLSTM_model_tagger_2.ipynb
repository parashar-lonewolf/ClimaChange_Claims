{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kashgari\n",
    "from kashgari.tasks.labeling import BiLSTM_Model\n",
    "from kashgari.embeddings import BertEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA\n",
    "# SAVE_DATA_clus_tr = \"Save/clus_bistlstm_dataset_train.csv\"\n",
    "# SAVE_DATA_clus_ts = \"Save/clus_bistlstm_dataset_test.csv\"\n",
    "# SAVE_DATA_clus_dv = \"Save/clus_bistlstm_dataset_dev.csv\"\n",
    "\n",
    "SAVE_DATA_noclus_tr = \"Save/noclus_bistlstm_dataset_train.csv\"\n",
    "SAVE_DATA_noclus_ts = \"Save/noclus_bistlstm_dataset_test.csv\"\n",
    "SAVE_DATA_noclus_dv = \"Save/noclus_bistlstm_dataset_dev.csv\"\n",
    "\n",
    "train = open(SAVE_DATA_noclus_tr).read()\n",
    "test = open(SAVE_DATA_noclus_ts).read()\n",
    "val = open(SAVE_DATA_noclus_dv).read()\n",
    "\n",
    "def file_convert2format(file):\n",
    "    split_file = file.split(\"\\n\\t\\n\")\n",
    "    t_x = []\n",
    "    t_y = []\n",
    "    for sent in split_file:\n",
    "        t_x.append([])\n",
    "        t_y.append([])\n",
    "        sent_split = sent.split(\"\\n\")\n",
    "        for lines in sent_split:\n",
    "            line_split = lines.split(\"\\t\")\n",
    "            t_x[-1].append(line_split[0])\n",
    "            t_y[-1].append(line_split[1])\n",
    "            \n",
    "    return(t_x,t_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = file_convert2format(train)\n",
    "test_x, test_y = file_convert2format(test)\n",
    "valid_x, valid_y = file_convert2format(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 01:30:29,394 [DEBUG] kashgari - ------------------------------------------------\n",
      "2021-05-05 01:30:29,395 [DEBUG] kashgari - Loaded transformer model's vocab\n",
      "2021-05-05 01:30:29,396 [DEBUG] kashgari - config_path       : BERTmodels/cased_L-12_H-768_A-12/bert_config.json\n",
      "2021-05-05 01:30:29,397 [DEBUG] kashgari - vocab_path      : BERTmodels/cased_L-12_H-768_A-12/vocab.txt\n",
      "2021-05-05 01:30:29,398 [DEBUG] kashgari - checkpoint_path : BERTmodels/cased_L-12_H-768_A-12/bert_model.ckpt\n",
      "2021-05-05 01:30:29,399 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]', '[unused49]']\n",
      "2021-05-05 01:30:29,399 [DEBUG] kashgari - ------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_blstm': {'units': 128, 'return_sequences': True}, 'layer_dropout': {'rate': 0.4}, 'layer_time_distributed': {}, 'layer_activation': {'activation': 'softmax'}}\n"
     ]
    }
   ],
   "source": [
    "## using pretrained embeddings to fine tune for task\n",
    "bert_embed = BertEmbedding('BERTmodels/cased_L-12_H-768_A-12')\n",
    "model = BiLSTM_Model()\n",
    "hyper = model.default_hyper_parameters()\n",
    "\n",
    "hyper['layer_blstm']['units'] = 128\n",
    "hyper['layer_dropout']['rate'] = 0.4\n",
    "hyper['layer_activation']['activation'] = 'softmax'\n",
    "model = BiLSTM_Model(bert_embed, sequence_length=100,hyper_parameters=hyper)\n",
    "\n",
    "print(hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing text vocab dict: 100%|██████████| 3081/3081 [00:00<00:00, 85297.46it/s]\n",
      "Preparing text vocab dict: 100%|██████████| 410/410 [00:00<00:00, 78241.26it/s]\n",
      "2021-05-05 01:30:35,628 [DEBUG] kashgari - --- Build vocab dict finished, Total: 3279 ---\n",
      "2021-05-05 01:30:35,629 [DEBUG] kashgari - Top-10: ['[PAD]', '[UNK]', '[CLS]', '[SEP]', 'the', ',', '.', 'to', 'of', 'and']\n",
      "Preparing text vocab dict: 100%|██████████| 3081/3081 [00:00<00:00, 123424.33it/s]\n",
      "Preparing text vocab dict: 100%|██████████| 410/410 [00:00<00:00, 112972.32it/s]\n",
      "2021-05-05 01:30:35,665 [DEBUG] kashgari - --- Build vocab dict finished, Total: 7 ---\n",
      "2021-05-05 01:30:35,666 [DEBUG] kashgari - Top-10: ['[PAD]', 'O', 'I-CLAIM', 'I-ACT', 'B-CLAIM', 'B-ACT', '']\n",
      "2021-05-05 01:30:41,548 [DEBUG] kashgari - fit input shape: (2, 64, 100)\n",
      "2021-05-05 01:30:41,549 [DEBUG] kashgari - fit input shape: (64, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "48/48 [==============================] - 197s 4s/step - loss: 0.2184 - accuracy: 0.7770 - val_loss: 0.0517 - val_accuracy: 0.9573\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 171s 4s/step - loss: 0.0963 - accuracy: 0.8981 - val_loss: 0.0543 - val_accuracy: 0.9571\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 170s 4s/step - loss: 0.0746 - accuracy: 0.9122 - val_loss: 0.0418 - val_accuracy: 0.9612\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 170s 4s/step - loss: 0.0713 - accuracy: 0.9066 - val_loss: 0.0424 - val_accuracy: 0.9597\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 170s 4s/step - loss: 0.0617 - accuracy: 0.9204 - val_loss: 0.0379 - val_accuracy: 0.9578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa00846eac8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 01:45:24,178 [WARNING] kashgari - Sequence length is None, will use the max length of the samples, which is 95\n",
      "2021-05-05 01:45:24,200 [DEBUG] kashgari - predict seq_length: None, input: (2, 617, 95)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 25 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9fe7749620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "20/20 [==============================] - 33s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 01:45:57,537 [DEBUG] kashgari - predict output: (617, 95)\n",
      "2021-05-05 01:45:57,539 [DEBUG] kashgari - predict output argmax: [[0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " ...\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "    CLAIM     0.0658    0.0581    0.0617        86\n",
      "      ACT     0.1818    0.0615    0.0920        65\n",
      "\n",
      "micro avg     0.0918    0.0596    0.0723       151\n",
      "macro avg     0.1157    0.0596    0.0747       151\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'detail': {'CLAIM': {'precision': 0.06578947368421052,\n",
       "   'recall': 0.05813953488372093,\n",
       "   'f1-score': 0.06172839506172839,\n",
       "   'support': 86},\n",
       "  'ACT': {'precision': 0.18181818181818182,\n",
       "   'recall': 0.06153846153846154,\n",
       "   'f1-score': 0.09195402298850576,\n",
       "   'support': 65}},\n",
       " 'precision': 0.11573560632466175,\n",
       " 'recall': 0.059602649006622516,\n",
       " 'f1-score': 0.07473942695073853,\n",
       " 'support': 151}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 05:09:41,962 [DEBUG] kashgari - ------------------------------------------------\n",
      "2021-05-05 05:09:41,963 [DEBUG] kashgari - Loaded transformer model's vocab\n",
      "2021-05-05 05:09:41,964 [DEBUG] kashgari - config_path       : BERTmodels/cased_L-12_H-768_A-12/bert_config.json\n",
      "2021-05-05 05:09:41,965 [DEBUG] kashgari - vocab_path      : BERTmodels/cased_L-12_H-768_A-12/vocab.txt\n",
      "2021-05-05 05:09:41,965 [DEBUG] kashgari - checkpoint_path : BERTmodels/cased_L-12_H-768_A-12/bert_model.ckpt\n",
      "2021-05-05 05:09:41,966 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]', '[unused49]']\n",
      "2021-05-05 05:09:41,967 [DEBUG] kashgari - ------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model data will save to 'saved_act_claim_model' folder\n",
    "# model.save('saved_act_claim_model_1')\n",
    "loaded_model = BiLSTM_Model.load_model('saved_act_claim_model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 05:10:51,567 [DEBUG] kashgari - predict seq_length: None, input: (2, 1, 19)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'\", \"'\", 'This', 'characteristic', 'delusion', 'of', 'imperial', 'power', 'is', 'to', 'confuse', 'global', 'power', 'with', 'global', 'domination', '.']\n",
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 05:10:56,355 [DEBUG] kashgari - predict output: (1, 19)\n",
      "2021-05-05 05:10:56,356 [DEBUG] kashgari - predict output argmax: [[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load saved model\n",
    "print(test_x[133])\n",
    "loaded_model.predict(test_x[133:134])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bilstm_crf",
   "language": "python",
   "name": "bilstm_crf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
