{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kashgari\n",
    "from kashgari.tasks.labeling import BiLSTM_Model\n",
    "from kashgari.embeddings import BertEmbedding\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA\n",
    "# SAVE_DATA_clus_tr = \"Save/clus_bistlstm_dataset_train.csv\"\n",
    "# SAVE_DATA_clus_ts = \"Save/clus_bistlstm_dataset_test.csv\"\n",
    "# SAVE_DATA_clus_dv = \"Save/clus_bistlstm_dataset_dev.csv\"\n",
    "\n",
    "SAVE_DATA_noclus_tr = \"Save/noclus_bistlstm_dataset_train.csv\"\n",
    "SAVE_DATA_noclus_ts = \"Save/noclus_bistlstm_dataset_test.csv\"\n",
    "SAVE_DATA_noclus_dv = \"Save/noclus_bistlstm_dataset_dev.csv\"\n",
    "\n",
    "train = open(SAVE_DATA_noclus_tr).read()\n",
    "test = open(SAVE_DATA_noclus_ts).read()\n",
    "val = open(SAVE_DATA_noclus_dv).read()\n",
    "\n",
    "def file_convert2format(file):\n",
    "    split_file = file.split(\"\\n\\t\\n\")\n",
    "    t_x = []\n",
    "    t_y = []\n",
    "    for sent in split_file:\n",
    "        t_x.append([])\n",
    "        t_y.append([])\n",
    "        sent_split = sent.split(\"\\n\")\n",
    "        for lines in sent_split:\n",
    "            line_split = lines.split(\"\\t\")\n",
    "            t_x[-1].append(line_split[0])\n",
    "            t_y[-1].append(line_split[1])\n",
    "            \n",
    "    return(t_x,t_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = file_convert2format(train)\n",
    "test_x, test_y = file_convert2format(test)\n",
    "valid_x, valid_y = file_convert2format(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "total_x = np.array(list(train_x + test_x + valid_x))\n",
    "total_y = np.array(list(train_y + test_y + valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4108\n",
      "4108\n",
      "617 3081 410\n"
     ]
    }
   ],
   "source": [
    "print(len(total_x))\n",
    "print(len(total_y))\n",
    "index = np.array(list(range(len(total_x))))    \n",
    "\n",
    "## shuffling the dataset\n",
    "np.random.shuffle(index)\n",
    "total_x = total_x[index]\n",
    "total_y = total_y[index]\n",
    "\n",
    "## dividing the dataset\n",
    "train = int(len(total_x)*0.75)          ## 75% of the 100%\n",
    "val = int((len(total_x) - train)*0.4)  ## 40% of the 30%\n",
    "test = (len(total_x)-train-val)        ## 60% of the 30%\n",
    "print(test,train,val)\n",
    "\n",
    "## the dataset\n",
    "## tokens\n",
    "train_x = list(total_x[:train])\n",
    "test_x = list(total_x[train:(train+test)])\n",
    "valid_x = list(total_x[(train+test):])\n",
    "\n",
    "## labels\n",
    "train_y = list(total_y[:train])\n",
    "test_y = list(total_y[train:(train+test)])\n",
    "valid_y = list(total_y[(train+test):])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 06:12:04,283 [DEBUG] kashgari - ------------------------------------------------\n",
      "2021-05-05 06:12:04,284 [DEBUG] kashgari - Loaded transformer model's vocab\n",
      "2021-05-05 06:12:04,285 [DEBUG] kashgari - config_path       : BERTmodels/cased_L-12_H-768_A-12/bert_config.json\n",
      "2021-05-05 06:12:04,286 [DEBUG] kashgari - vocab_path      : BERTmodels/cased_L-12_H-768_A-12/vocab.txt\n",
      "2021-05-05 06:12:04,286 [DEBUG] kashgari - checkpoint_path : BERTmodels/cased_L-12_H-768_A-12/bert_model.ckpt\n",
      "2021-05-05 06:12:04,287 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]', '[unused49]']\n",
      "2021-05-05 06:12:04,288 [DEBUG] kashgari - ------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_blstm': {'units': 32, 'return_sequences': True}, 'layer_dropout': {'rate': 0.4}, 'layer_time_distributed': {}, 'layer_activation': {'activation': 'softmax'}}\n"
     ]
    }
   ],
   "source": [
    "## using pretrained embeddings to fine tune for task\n",
    "bert_embed = BertEmbedding('BERTmodels/cased_L-12_H-768_A-12')\n",
    "model = BiLSTM_Model()\n",
    "hyper = model.default_hyper_parameters()\n",
    "\n",
    "hyper['layer_blstm']['units'] = 32\n",
    "hyper['layer_dropout']['rate'] = 0.6\n",
    "hyper['layer_activation']['activation'] = 'softmax'\n",
    "model = BiLSTM_Model(bert_embed, sequence_length=32,hyper_parameters=hyper)\n",
    "\n",
    "print(hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## model train for 50 epochs\n",
    "# model.fit(train_x, train_y, valid_x, valid_y,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 10:03:29,684 [WARNING] kashgari - Sequence length is None, will use the max length of the samples, which is 93\n",
      "2021-05-05 10:03:29,705 [DEBUG] kashgari - predict seq_length: None, input: (2, 617, 93)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 32s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 10:04:02,164 [DEBUG] kashgari - predict output: (617, 93)\n",
      "2021-05-05 10:04:02,166 [DEBUG] kashgari - predict output argmax: [[0 1 1 ... 2 2 2]\n",
      " [0 1 1 ... 2 2 2]\n",
      " [0 1 1 ... 2 2 2]\n",
      " ...\n",
      " [0 1 1 ... 2 2 2]\n",
      " [0 1 1 ... 2 2 2]\n",
      " [0 1 1 ... 2 2 2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      ACT     0.1429    0.0366    0.0583        82\n",
      "    CLAIM     0.0515    0.0318    0.0394       157\n",
      "\n",
      "micro avg     0.0678    0.0335    0.0448       239\n",
      "macro avg     0.0829    0.0335    0.0458       239\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'detail': {'ACT': {'precision': 0.14285714285714285,\n",
       "   'recall': 0.036585365853658534,\n",
       "   'f1-score': 0.058252427184466014,\n",
       "   'support': 82},\n",
       "  'CLAIM': {'precision': 0.05154639175257732,\n",
       "   'recall': 0.03184713375796178,\n",
       "   'f1-score': 0.03937007874015747,\n",
       "   'support': 157}},\n",
       " 'precision': 0.08287476660853703,\n",
       " 'recall': 0.03347280334728033,\n",
       " 'f1-score': 0.045848541386321905,\n",
       " 'support': 239}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 10:14:00,231 [INFO] kashgari - model saved to /project/ClimaChange_Claims/saved_act_claim_model_ep50\n",
      "2021-05-05 10:14:00,333 [DEBUG] kashgari - ------------------------------------------------\n",
      "2021-05-05 10:14:00,334 [DEBUG] kashgari - Loaded transformer model's vocab\n",
      "2021-05-05 10:14:00,335 [DEBUG] kashgari - config_path       : BERTmodels/cased_L-12_H-768_A-12/bert_config.json\n",
      "2021-05-05 10:14:00,336 [DEBUG] kashgari - vocab_path      : BERTmodels/cased_L-12_H-768_A-12/vocab.txt\n",
      "2021-05-05 10:14:00,337 [DEBUG] kashgari - checkpoint_path : BERTmodels/cased_L-12_H-768_A-12/bert_model.ckpt\n",
      "2021-05-05 10:14:00,337 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]', '[unused49]']\n",
      "2021-05-05 10:14:00,338 [DEBUG] kashgari - ------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model data will save to 'saved_act_claim_model' folder\n",
    "# model.save('saved_act_claim_model_ep50')\n",
    "loaded_model = BiLSTM_Model.load_model('saved_act_claim_model_ep50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # To continue training, compile the newly loaded model first and train for 250 more epochs\n",
    "# loaded_model.compile_model()\n",
    "# loaded_model.fit(train_x, train_y, valid_x, valid_y, epochs = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 14:15:49,487 [DEBUG] kashgari - predict seq_length: None, input: (2, 617, 93)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 33s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 14:16:22,868 [DEBUG] kashgari - predict output: (617, 93)\n",
      "2021-05-05 14:16:22,869 [DEBUG] kashgari - predict output argmax: [[0 1 1 ... 4 4 4]\n",
      " [0 1 1 ... 4 4 4]\n",
      " [0 1 1 ... 4 4 4]\n",
      " ...\n",
      " [0 1 1 ... 4 4 4]\n",
      " [0 1 1 ... 4 4 4]\n",
      " [0 1 1 ... 4 4 4]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      ACT     0.2162    0.0976    0.1345        82\n",
      "    CLAIM     0.0303    0.0191    0.0234       157\n",
      "\n",
      "micro avg     0.0809    0.0460    0.0587       239\n",
      "macro avg     0.0941    0.0460    0.0615       239\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'detail': {'ACT': {'precision': 0.21621621621621623,\n",
       "   'recall': 0.0975609756097561,\n",
       "   'f1-score': 0.13445378151260506,\n",
       "   'support': 82},\n",
       "  'CLAIM': {'precision': 0.030303030303030304,\n",
       "   'recall': 0.01910828025477707,\n",
       "   'f1-score': 0.0234375,\n",
       "   'support': 157}},\n",
       " 'precision': 0.09408914429834932,\n",
       " 'recall': 0.04602510460251046,\n",
       " 'f1-score': 0.061526768134031865,\n",
       " 'support': 239}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loaded_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 14:17:45,806 [INFO] kashgari - model saved to /project/ClimaChange_Claims/saved_act_claim_model_BERTuncased_ep300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/project/ClimaChange_Claims/saved_act_claim_model_BERTuncased_ep300'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model data will save to 'saved_act_claim_model' folder\n",
    "loaded_model.save('saved_act_claim_model_BERTuncased_ep300')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bilstm_crf",
   "language": "python",
   "name": "bilstm_crf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
