<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE nitf SYSTEM "http://www.nitf.org/IPTC/NITF/3.3/specification/dtd/nitf-3-3.dtd">
<nitf change.date="June 10, 2005" change.time="19:30" version="-//IPTC//DTD NITF 3.3//EN">
  <head>
    <title>When Scientific Predictions Are So Good They're Bad</title>
    <meta content="29PRED$01" name="slug"/>
    <meta content="29" name="publication_day_of_month"/>
    <meta content="9" name="publication_month"/>
    <meta content="1998" name="publication_year"/>
    <meta content="Tuesday" name="publication_day_of_week"/>
    <meta content="Science Desk" name="dsk"/>
    <meta content="1" name="print_page_number"/>
    <meta content="F" name="print_section"/>
    <meta content="2" name="print_column"/>
    <meta content="Science; Health" name="online_sections"/>
    <docdata>
      <doc-id id-string="1050125"/>
      <doc.copyright holder="The New York Times" year="1998"/>
      <identified-content>
        <classifier class="indexing_service" type="descriptor">Forecasts</classifier>
        <person class="indexing_service">Stevens, William K</person>
        <classifier class="online_producer" type="taxonomic_classifier">Top/News</classifier>
        <classifier class="online_producer" type="taxonomic_classifier">Top/News/U.S./Rockies</classifier>
        <classifier class="online_producer" type="taxonomic_classifier">Top/News/Science</classifier>
        <classifier class="online_producer" type="taxonomic_classifier">Top/News/Health</classifier>
        <classifier class="online_producer" type="general_descriptor">Forecasts</classifier>
        <classifier class="online_producer" type="general_descriptor">Economic Conditions and Trends</classifier>
      </identified-content>
    </docdata>
    <pubdata date.publication="19980929T000000" ex-ref="http://query.nytimes.com/gst/fullpage.html?res=9C05EEDA1039F93AA1575AC0A96E958260" item-length="1754" name="The New York Times" unit-of-measure="word"/>
  </head>
  <body>
    <body.head>
      <hedline>
        <hl1>When Scientific Predictions Are So Good They're Bad</hl1>
      </hedline>
      <byline class="print_byline">By WILLIAM K. STEVENS</byline>
      <byline class="normalized_byline">Stevens, William K</byline>
      <abstract>
        <p>Problem of error in making scientific predictions is topic of workshop this month at Estes Park, Colo; experts say that whether problem is climate change, earthquakes, droughts or floods, tendency to overlook uncertainties, margins of error and ranges of probability can lead to damaging misjudgments; say that problem arises because decision makers sometimes want to avoid making hard choices in uncertain situations--they would rather place responsibility on predictors; photo (M)</p>
      </abstract>
    </body.head>
    <body.content>
      <block class="lead_paragraph">
        <p>NOAH had it easy. He got his prediction straight from the horse's mouth and was left in no doubt about what to do.</p>
        <p>But when the Red River of the North was rising to record levels in the spring of 1997, the citizens and officials of Grand Forks, N.D., were not so privileged. They had to rely on scientists' predictions about how high the water would rise. And in this case, Federal experts say, the flood forecast may  have been issued and used in a way that made things worse.</p>
      </block>
      <block class="full_text">
        <p>NOAH had it easy. He got his prediction straight from the horse's mouth and was left in no doubt about what to do.</p>
        <p>But when the Red River of the North was rising to record levels in the spring of 1997, the citizens and officials of Grand Forks, N.D., were not so privileged. They had to rely on scientists' predictions about how high the water would rise. And in this case, Federal experts say, the flood forecast may  have been issued and used in a way that made things worse.</p>
        <p>The problem, the experts said, was that more precision was assigned to the forecast than was warranted. Officials and citizens tended to take as gospel an oft-repeated National Weather Service prediction that the river would crest at a record 49 feet. Actually, there was a wider range of probabilities; the river ultimately crested at 54 feet, forcing 50,000 people to abandon their homes fast. The 49-foot forecast had lulled the town into a false sense of security, said Dr. Roger A. Pielke Jr. of the National Center for Atmospheric Research in Boulder, Colo., a consultant on a subsequent inquiry by the weather service.</p>
        <p>In fixating on the single number of 49 feet, the people involved in the Grand Forks disaster made a common error in the use of predictions and forecasts, experts who have studied the case say. It was, they say, a case of what Alfred North Whitehead, the mathematician and philosopher, once termed ''misplaced concreteness.'' And whether the problem is climate change, earthquakes, droughts or floods, they say the tendency to overlook uncertainties, margins of error and ranges of probability can lead to damaging misjudgments.</p>
        <p>The problem was the topic of a workshop this month at Estes Park, Colo. In part, participants said, the problem arises  because decision makers sometimes want to avoid making hard choices in uncertain situations. They would rather place responsibility on the predictors.</p>
        <p>Scientifically based predictions, typically using computerized mathematical models, have become pervasive in modern society. But only recently has much attention been paid to the proper use -- and misuse -- of predictions. The Estes Park  workshop, of which Dr. Pielke was an organizer, was an attempt to come to grips with the question. The workshop was sponsored by the Geological Society of America and the National Center for Atmospheric Research.</p>
        <p>People have predicted and prophesied for millenniums, of course, through means ranging from the visions of shamans and the warnings of biblical prophets to the examination of animal entrails. With the arrival of modern science, people teased out fundamental laws of physical and chemical behavior and used them to make better and better predictions.</p>
        <p>But once science moves beyond the relatively deterministic processes of physics and chemistry, prediction gets more complicated and chancier. The earth's atmosphere, for instance, often frustrates efforts to predict the weather and long-term climatic changes because scientists have not nailed down all of its physical workings and because a substantial measure of chaotic unpredictability is inherent in the climate system. The result is a considerable range of uncertainty, much more so than is popularly associated with science. So while computer modeling has often made reasonable predictions possible, they are always uncertain; results are by definition a model of reality, not reality itself.</p>
        <p>The accuracy of predictions varies widely. Some, like earthquake forecasts, have proved so disappointing that experts have turned instead to forecasting longer-term earthquake potential in a general sense and issuing last-second warnings to distant communities once a quake has begun.</p>
        <p>In some cases, the success of a prediction is near impossible to judge. For instance, it will take thousands of years to know whether the environmental effects of buried radioactive waste will be as predicted.</p>
        <p>On the other hand, daily weather forecasts are checked almost instantly and are used to improve the next day's forecast. But weather forecasting is also a success, the assembled experts agreed, because people know its shortcomings and take them into consideration. Weather forecasts ''are wrong a lot of the time, but people expect that and they use them accordingly,'' said Robert Ravenscroft, a Nebraska rancher who attended the workshop as a ''user'' of predictions.</p>
        <p>A prediction is to be distrusted, workshop participants said, when it is made by the group that will use it as a basis for policy making -- especially when the prediction is made after the policy decision has been  taken. In one example offered at the workshop, modeling studies purported to show no harmful environmental effects from a gold mine that a company had decided to dig.</p>
        <p>Another type of prediction miscue emerged last March in connection with asteroids, the workshop participants were told by Dr. Clark R. Chapman, a planetary scientist at the Southwest Research Institute in Boulder. An astronomer erroneously calculated that there was a chance of one-tenth of 1 percent that a mile-wide asteroid would strike Earth in 30 years. The prediction created an international stir but was withdrawn a day later after further evidence turned up.</p>
        <p>This ''uncharacteristically bad'' prediction, said Dr. Chapman, would not have been issued had it been subjected to normal review by the forecaster's scientific peers. But, he said, there was no peer-review apparatus set up to make sure that ''off-the-wall predictions don't get out.'' (Such a committee has since been established by NASA.)</p>
        <p>Most sins committed in the name of prediction, however, appear to stem from the uncertainty inherent in almost all forecasts. ''People don't understand error bars,'' said one scientist, referring to margins of error.  Global climate change and the Red River flood offer two cases in point.</p>
        <p>Computer models of the climate system are the major instruments used by scientists to project changes in climate that might result from increasing atmospheric concentrations of heat-trapping gases, like carbon dioxide, emitted by the burning of fossil fuels.</p>
        <p>Basing its forecast on the models, a panel of scientists set up by the United Nations has projected that the average surface temperature of the globe will rise by 2 to 6 degrees Fahrenheit, with a best estimate of  3.5 degrees, in the next century, and more after that. This compares with a rise of 5 to 9 degrees since the depths of the last ice age. The temperature has increased by about 1 degree over the last century.</p>
        <p>But the magnitude and nature of any climate changes produced by any given amount of carbon dioxide are uncertain. Moreover, it is unclear how much of the gas will be emitted over the next few years, said Dr. Jerry D. Mahlman, a workshop participant who directs the National Oceanic and Atmospheric Administration's Geophysical Fluid Dynamics Laboratory at Princeton, N.J. The laboratory is one of the world's major climate modeling centers, and the oldest.</p>
        <p>This uncertainty opens the way for two equal and opposite sins of misinterpretation. ''The uncertainty is used as a reason for governments not to act,'' in the words of Dr. Ronald D. Brunner, a political scientist at the University of Colorado at Boulder. On the other hand, people often put too much reliance on the precise numbers.</p>
        <p>In the debate over climate change, the tendency is to state all the uncertainties and caveats associated with the climate model projections -- and then forget about them, said Dr. Steve Rayner, a specialist in global climate change in the District of Columbia office of the Pacific Northwest National Laboratory. This creates a ''fallacy of misplaced confidence,'' he said, explaining that the specific numbers in the model forecasts ''take on a validity not allowed by the caveats.'' This tendency to focus unwisely on specific numbers was termed ''fallacious quantification'' by Dr. Naomi Oreskes, a historian at the University of California at San Diego.</p>
        <p>Where uncertainty rules, many at the workshop said, it might be better to stay away from specific numbers altogether and issue a more generalized forecast. In climate change, this might mean using the models as a general indication of the direction in which the climate is going (whether it is warming, for instance) and of the approximate magnitude of the change, while taking the numbers with a grain of salt.</p>
        <p>None of which means that the models are not a helpful guide to public policy, said Dr. Mahlman and other experts. For example, the models say that a warming atmosphere, like today's, will produce heavier rains and snows, and some evidence suggests that this is already happening in the United States, possibly contributing to damaging floods. Local planners might be well advised to consider this, Dr. Mahlman said.</p>
        <p>One problem in Grand Forks was that lack of experience with such a damaging flood aggravated the uncertainty of the flood forecast. Because the river had never before been observed at the 54-foot level, the models on which the prediction was based were ''flying blind,'' said Dr. Pielke; there was no historical basis on which to produce a reliable forecast.</p>
        <p>But this was apparently lost on local officials and the public, who focused on the specific forecast of a 49-foot crest. This number was repeated so often, according to the report of an inquiry by the National Weather Service, that it ''contributed to an impression of certainty.'' Actually, the report said, the 49-foot figure ''created a sense of complacency,'' because it was only a fraction of a foot higher than the record flood of 1979, which the city had survived.</p>
        <p>''They came down with this number and people fixated on it,'' Tom Mulhern, the Grand Forks communications officer, said in an interview.  The dikes protecting the city had been built up with sandbags to contain a 52-foot crest, and everyone figured the town was safe, he said.</p>
        <p>It is difficult to know what might have happened had the uncertainty of the forecast been better communicated. But it is possible, said Mr. Mulhern, that the dikes might have been sufficiently enlarged and people might have taken more steps to preserve their possessions. As it was, he said, ''some people didn't leave till the water was coming down the street.''</p>
      </block>
    </body.content>
  </body>
</nitf>
