{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "from kashgari.tasks.labeling import BiLSTM_Model\n",
    "from kashgari.embeddings import BertEmbedding\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA\n",
    "# SAVE_DATA_clus_tr = \"Save/clus_bistlstm_dataset_train.csv\"\n",
    "# SAVE_DATA_clus_ts = \"Save/clus_bistlstm_dataset_test.csv\"\n",
    "# SAVE_DATA_clus_dv = \"Save/clus_bistlstm_dataset_dev.csv\"\n",
    "\n",
    "SAVE_DATA_noclus_tr = \"Save/noclus_bistlstm_dataset_train.csv\"\n",
    "SAVE_DATA_noclus_ts = \"Save/noclus_bistlstm_dataset_test.csv\"\n",
    "SAVE_DATA_noclus_dv = \"Save/noclus_bistlstm_dataset_dev.csv\"\n",
    "\n",
    "train = open(SAVE_DATA_noclus_tr).read()\n",
    "test = open(SAVE_DATA_noclus_ts).read()\n",
    "val = open(SAVE_DATA_noclus_dv).read()\n",
    "\n",
    "def file_convert2format(file):\n",
    "    split_file = file.split(\"\\n\\t\\n\")\n",
    "    t_x = []\n",
    "    t_y = []\n",
    "    for sent in split_file:\n",
    "        t_x.append([])\n",
    "        t_y.append([])\n",
    "        sent_split = sent.split(\"\\n\")\n",
    "        for lines in sent_split:\n",
    "            line_split = lines.split(\"\\t\")\n",
    "            t_x[-1].append(line_split[0])\n",
    "            t_y[-1].append(line_split[1])\n",
    "            \n",
    "    return(t_x,t_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = file_convert2format(train)\n",
    "test_x, test_y = file_convert2format(test)\n",
    "valid_x, valid_y = file_convert2format(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "total_x = np.array(list(train_x + test_x + valid_x))\n",
    "total_y = np.array(list(train_y + test_y + valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4108\n",
      "4108\n",
      "617 3081 410\n"
     ]
    }
   ],
   "source": [
    "print(len(total_x))\n",
    "print(len(total_y))\n",
    "index = np.array(list(range(len(total_x))))    \n",
    "\n",
    "## shuffling the dataset\n",
    "np.random.shuffle(index)\n",
    "total_x = total_x[index]\n",
    "total_y = total_y[index]\n",
    "\n",
    "## dividing the dataset\n",
    "train = int(len(total_x)*0.75)          ## 75% of the 100%\n",
    "val = int((len(total_x) - train)*0.4)  ## 40% of the 30%\n",
    "test = (len(total_x)-train-val)        ## 60% of the 30%\n",
    "print(test,train,val)\n",
    "\n",
    "## the dataset\n",
    "## tokens\n",
    "train_x = list(total_x[:train])\n",
    "test_x = list(total_x[train:(train+test)])\n",
    "valid_x = list(total_x[(train+test):])\n",
    "\n",
    "## labels\n",
    "train_y = list(total_y[:train])\n",
    "test_y = list(total_y[train:(train+test)])\n",
    "valid_y = list(total_y[(train+test):])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 04:26:35,036 [DEBUG] kashgari - ------------------------------------------------\n",
      "2021-05-05 04:26:35,037 [DEBUG] kashgari - Loaded transformer model's vocab\n",
      "2021-05-05 04:26:35,038 [DEBUG] kashgari - config_path       : BERTmodels/BERT_Tiny_2_128/bert_config.json\n",
      "2021-05-05 04:26:35,039 [DEBUG] kashgari - vocab_path      : BERTmodels/BERT_Tiny_2_128/vocab.txt\n",
      "2021-05-05 04:26:35,040 [DEBUG] kashgari - checkpoint_path : BERTmodels/BERT_Tiny_2_128/bert_model.ckpt\n",
      "2021-05-05 04:26:35,040 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused0]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]']\n",
      "2021-05-05 04:26:35,041 [DEBUG] kashgari - ------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_blstm': {'units': 64, 'return_sequences': True}, 'layer_dropout': {'rate': 0.35}, 'layer_time_distributed': {}, 'layer_activation': {'activation': 'softmax'}}\n"
     ]
    }
   ],
   "source": [
    "## using pretrained embeddings to fine tune for task\n",
    "## BERT_Tiny_2_128\n",
    "## cased_L-12_H-768_A-12\n",
    "\n",
    "bert_embed = BertEmbedding('BERTmodels/BERT_Tiny_2_128')\n",
    "model = BiLSTM_Model()\n",
    "hyper = model.default_hyper_parameters()\n",
    "\n",
    "hyper['layer_blstm']['units'] = 64\n",
    "hyper['layer_dropout']['rate'] = 0.35\n",
    "hyper['layer_activation']['activation'] = 'softmax'\n",
    "model = BiLSTM_Model(bert_embed, sequence_length=64,hyper_parameters=hyper)\n",
    "\n",
    "print(hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing text vocab dict: 100%|██████████| 3081/3081 [00:00<00:00, 85329.00it/s]\n",
      "Preparing text vocab dict: 100%|██████████| 410/410 [00:00<00:00, 89720.07it/s]\n",
      "2021-05-05 04:26:35,786 [DEBUG] kashgari - --- Build vocab dict finished, Total: 3319 ---\n",
      "2021-05-05 04:26:35,787 [DEBUG] kashgari - Top-10: ['[PAD]', '[UNK]', '[CLS]', '[SEP]', 'the', ',', '.', 'to', 'of', 'and']\n",
      "Preparing text vocab dict: 100%|██████████| 3081/3081 [00:00<00:00, 122980.34it/s]\n",
      "Preparing text vocab dict: 100%|██████████| 410/410 [00:00<00:00, 112337.64it/s]\n",
      "2021-05-05 04:26:35,823 [DEBUG] kashgari - --- Build vocab dict finished, Total: 7 ---\n",
      "2021-05-05 04:26:35,823 [DEBUG] kashgari - Top-10: ['[PAD]', 'O', 'I-CLAIM', 'I-ACT', 'B-CLAIM', 'B-ACT', '']\n",
      "2021-05-05 04:26:38,064 [DEBUG] kashgari - fit input shape: (2, 64, 64)\n",
      "2021-05-05 04:26:38,066 [DEBUG] kashgari - fit input shape: (64, 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "48/48 [==============================] - 15s 147ms/step - loss: 0.3379 - accuracy: 0.7817 - val_loss: 0.1718 - val_accuracy: 0.9048\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 4s 89ms/step - loss: 0.1541 - accuracy: 0.9155 - val_loss: 0.1321 - val_accuracy: 0.9095\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 4s 89ms/step - loss: 0.1307 - accuracy: 0.9218 - val_loss: 0.1145 - val_accuracy: 0.9190\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 4s 90ms/step - loss: 0.1291 - accuracy: 0.9207 - val_loss: 0.1210 - val_accuracy: 0.9130\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 4s 90ms/step - loss: 0.1189 - accuracy: 0.9210 - val_loss: 0.1179 - val_accuracy: 0.9108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3b5e6d8d30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 04:27:10,634 [WARNING] kashgari - Sequence length is None, will use the max length of the samples, which is 88\n",
      "2021-05-05 04:27:10,650 [DEBUG] kashgari - predict seq_length: None, input: (2, 617, 88)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 04:27:14,165 [DEBUG] kashgari - predict output: (617, 88)\n",
      "2021-05-05 04:27:14,166 [DEBUG] kashgari - predict output argmax: [[0 1 1 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " ...\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      ACT     0.0000    0.0000    0.0000       102\n",
      "    CLAIM     0.0690    0.0132    0.0222       151\n",
      "\n",
      "micro avg     0.0690    0.0079    0.0142       253\n",
      "macro avg     0.0412    0.0079    0.0133       253\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'detail': {'ACT': {'precision': 0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0,\n",
       "   'support': 102},\n",
       "  'CLAIM': {'precision': 0.06896551724137931,\n",
       "   'recall': 0.013245033112582781,\n",
       "   'f1-score': 0.022222222222222223,\n",
       "   'support': 151}},\n",
       " 'precision': 0.04116123756303666,\n",
       " 'recall': 0.007905138339920948,\n",
       " 'f1-score': 0.01326306543697848,\n",
       " 'support': 253}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 04:51:07,829 [INFO] kashgari - model saved to /project/ClimaChange_Claims/saved_act_claim_model_relu_1\n",
      "2021-05-05 04:51:07,936 [DEBUG] kashgari - ------------------------------------------------\n",
      "2021-05-05 04:51:07,937 [DEBUG] kashgari - Loaded transformer model's vocab\n",
      "2021-05-05 04:51:07,938 [DEBUG] kashgari - config_path       : BERTmodels/BERT_Tiny_2_128/bert_config.json\n",
      "2021-05-05 04:51:07,939 [DEBUG] kashgari - vocab_path      : BERTmodels/BERT_Tiny_2_128/vocab.txt\n",
      "2021-05-05 04:51:07,940 [DEBUG] kashgari - checkpoint_path : BERTmodels/BERT_Tiny_2_128/bert_model.ckpt\n",
      "2021-05-05 04:51:07,940 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused0]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]']\n",
      "2021-05-05 04:51:07,941 [DEBUG] kashgari - ------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model data will save to 'saved_act_claim_model' folder\n",
    "model.save('saved_act_claim_model_relu_1')\n",
    "loaded_model = BiLSTM_Model.load_model('saved_act_claim_model_relu_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 04:52:09,322 [DEBUG] kashgari - predict seq_length: None, input: (2, 1, 19)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thinking', 'further', ',', 'he', 'adds', ':', \"'\", \"'\", 'The', 'problem', 'is', ',', 'we', \"'ve\", 'gone', 'too', 'far', 'already', '.']\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 04:52:11,931 [DEBUG] kashgari - predict output: (1, 19)\n",
      "2021-05-05 04:52:11,933 [DEBUG] kashgari - predict output argmax: [[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load saved model\n",
    "print(test_x[12])\n",
    "loaded_model.predict(test_x[11:12])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bilstm_crf",
   "language": "python",
   "name": "bilstm_crf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
