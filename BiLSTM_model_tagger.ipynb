{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "from kashgari.tasks.labeling import BiLSTM_Model\n",
    "from kashgari.embeddings import BertEmbedding\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA\n",
    "# SAVE_DATA_clus_tr = \"Save/clus_bistlstm_dataset_train.csv\"\n",
    "# SAVE_DATA_clus_ts = \"Save/clus_bistlstm_dataset_test.csv\"\n",
    "# SAVE_DATA_clus_dv = \"Save/clus_bistlstm_dataset_dev.csv\"\n",
    "\n",
    "SAVE_DATA_noclus_tr = \"Save/noclus_bistlstm_dataset_train.csv\"\n",
    "SAVE_DATA_noclus_ts = \"Save/noclus_bistlstm_dataset_test.csv\"\n",
    "SAVE_DATA_noclus_dv = \"Save/noclus_bistlstm_dataset_dev.csv\"\n",
    "\n",
    "train = open(SAVE_DATA_noclus_tr).read()\n",
    "test = open(SAVE_DATA_noclus_ts).read()\n",
    "val = open(SAVE_DATA_noclus_dv).read()\n",
    "\n",
    "def file_convert2format(file):\n",
    "    split_file = file.split(\"\\n\\t\\n\")\n",
    "    t_x = []\n",
    "    t_y = []\n",
    "    for sent in split_file:\n",
    "        t_x.append([])\n",
    "        t_y.append([])\n",
    "        sent_split = sent.split(\"\\n\")\n",
    "        for lines in sent_split:\n",
    "            line_split = lines.split(\"\\t\")\n",
    "            t_x[-1].append(line_split[0])\n",
    "            t_y[-1].append(line_split[1])\n",
    "            \n",
    "    return(t_x,t_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = file_convert2format(train)\n",
    "test_x, test_y = file_convert2format(test)\n",
    "valid_x, valid_y = file_convert2format(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "total_x = np.array(list(train_x + test_x + valid_x))\n",
    "total_y = np.array(list(train_y + test_y + valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4108\n",
      "4108\n",
      "617 3081 410\n"
     ]
    }
   ],
   "source": [
    "print(len(total_x))\n",
    "print(len(total_y))\n",
    "index = np.array(list(range(len(total_x))))    \n",
    "\n",
    "## shuffling the dataset\n",
    "np.random.shuffle(index)\n",
    "total_x = total_x[index]\n",
    "total_y = total_y[index]\n",
    "\n",
    "## dividing the dataset\n",
    "train = int(len(total_x)*0.75)          ## 75% of the 100%\n",
    "val = int((len(total_x) - train)*0.4)  ## 40% of the 30%\n",
    "test = (len(total_x)-train-val)        ## 60% of the 30%\n",
    "print(test,train,val)\n",
    "\n",
    "## the dataset\n",
    "## tokens\n",
    "train_x = list(total_x[:train])\n",
    "test_x = list(total_x[train:(train+test)])\n",
    "valid_x = list(total_x[(train+test):])\n",
    "\n",
    "## labels\n",
    "train_y = list(total_y[:train])\n",
    "test_y = list(total_y[train:(train+test)])\n",
    "valid_y = list(total_y[(train+test):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_blstm': {'units': 32, 'return_sequences': True}, 'layer_dropout': {'rate': 0.8}, 'layer_time_distributed': {}, 'layer_activation': {'activation': 'softmax'}}\n"
     ]
    }
   ],
   "source": [
    "## using pretrained embeddings to fine tune for task\n",
    "## BERT_Tiny_2_128\n",
    "## cased_L-12_H-768_A-12\n",
    "\n",
    "bert_embed = BertEmbedding('BERTmodels/BERT_Tiny_2_128')\n",
    "model = BiLSTM_Model()\n",
    "hyper = model.default_hyper_parameters()\n",
    "\n",
    "hyper['layer_blstm']['units'] = 32\n",
    "hyper['layer_dropout']['rate'] = 0.8\n",
    "hyper['layer_activation']['activation'] = 'softmax'\n",
    "model = BiLSTM_Model(bert_embed, sequence_length=32,hyper_parameters=hyper)\n",
    "\n",
    "print(hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## training the model with our data for 1000 epochs\n",
    "# model.fit(train_x, train_y, valid_x, valid_y,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 14:31:49,353 [DEBUG] kashgari - predict seq_length: None, input: (2, 617, 94)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 14:31:50,335 [DEBUG] kashgari - predict output: (617, 94)\n",
      "2021-05-05 14:31:50,337 [DEBUG] kashgari - predict output argmax: [[0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " ...\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "    CLAIM     0.1414    0.0892    0.1094       157\n",
      "      ACT     0.1111    0.0114    0.0206        88\n",
      "\n",
      "micro avg     0.1389    0.0612    0.0850       245\n",
      "macro avg     0.1305    0.0612    0.0775       245\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'detail': {'CLAIM': {'precision': 0.1414141414141414,\n",
       "   'recall': 0.08917197452229299,\n",
       "   'f1-score': 0.10937499999999999,\n",
       "   'support': 157},\n",
       "  'ACT': {'precision': 0.1111111111111111,\n",
       "   'recall': 0.011363636363636364,\n",
       "   'f1-score': 0.020618556701030927,\n",
       "   'support': 88}},\n",
       " 'precision': 0.1305297876726448,\n",
       " 'recall': 0.06122448979591836,\n",
       " 'f1-score': 0.07749513465179886,\n",
       " 'support': 245}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 14:32:09,087 [DEBUG] kashgari - ------------------------------------------------\n",
      "2021-05-05 14:32:09,088 [DEBUG] kashgari - Loaded transformer model's vocab\n",
      "2021-05-05 14:32:09,089 [DEBUG] kashgari - config_path       : BERTmodels/BERT_Tiny_2_128/bert_config.json\n",
      "2021-05-05 14:32:09,090 [DEBUG] kashgari - vocab_path      : BERTmodels/BERT_Tiny_2_128/vocab.txt\n",
      "2021-05-05 14:32:09,091 [DEBUG] kashgari - checkpoint_path : BERTmodels/BERT_Tiny_2_128/bert_model.ckpt\n",
      "2021-05-05 14:32:09,091 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused0]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]']\n",
      "2021-05-05 14:32:09,092 [DEBUG] kashgari - ------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model data will save to 'saved_act_claim_model' folder\n",
    "# model.save('saved_act_claim_model_1000_dropout_0.8_BERTtiny_2')\n",
    "loaded_model = BiLSTM_Model.load_model('saved_act_claim_model_1000_dropout_0.8_BERTtiny_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 14:55:33,754 [DEBUG] kashgari - predict seq_length: None, input: (2, 1, 39)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'sort', 'of', 'fuzzy', 'thinking', 'provides', 'the', 'warm', 'illusion', 'of', 'saving', 'the', 'sky', ',', 'which', 'we', \"'re\", 'not', 'even', 'sure', 'needs', 'saving', ',', 'but', 'it', 'wo', \"n't\", 'have', 'any', 'impact', 'at', 'all', 'on', 'global', 'warming', ',', \"''\"]\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 14:55:33,823 [DEBUG] kashgari - predict output: (1, 39)\n",
      "2021-05-05 14:55:33,824 [DEBUG] kashgari - predict output argmax: [[0 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2\n",
      "  1 1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'O I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM O I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM O I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM I-CLAIM O O'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load predict model\n",
    "print(test_x[112])\n",
    "(\" \").join((loaded_model.predict(test_x[112:113]))[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bilstm_crf",
   "language": "python",
   "name": "bilstm_crf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
